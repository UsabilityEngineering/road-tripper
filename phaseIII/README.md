# Phase III: Prototypes and User Testing
### Written by Peter Menzies and Steven Mendez
Phase 3 of our research study included gathering some participants to do a walkthrough of tasks that we created to see how our application would flow. Throughout this phase, we made a consent form that the test subjects had to sign before doing the study. The study consisted of 3 tasks and some pre-task questions regarding the history of traveling. The pre-task questions gave us insight into who the user was and their experience with traveling. This gave us an idea of the different websites they used to plan their road trip. The next tasks were given so that we could gain some insight into how the app flows and where the rough parts of the application were. We were able to recognize the parts that needed to be reworked in order for the user to have a better UI experience.

## Methods
For our study, we had a total of 5 participants. Our goal was to test every single part of the application through the 3 tasks we assigned. Each task was designed to go through specific features we have on the application. Through the test, we were able to see that some buttons were, or features were not visible.

Task 1 
Now I want you to imagine you are planning a road trip for yourself and your
dog. You want to travel a maximum of 10 hours from your hometown of
Sacramento CA. you have a budget of 1000 dollars which includes gas,
campsites, food, and other miscellaneous expenses. Walk me through how you
would plan this road trip using the app.
  - The goal of this task was to get the user to test out the filters feature and navigate the map to find a destination. This was a really good question because it got the users to use the filters as well as the trip stats page to see how much money they would have spent going on this trip. There were some caveats as they were not able to make an actual itinerary and check the prices, so they had to use their imagination.


Task 2 
Imagine youâ€™re taking a road trip with your significant other, and you all plan
on staying in major cities and towns along the west coast. You all also plan on
stopping by some major sightseeing places and going to all the popular food
stops. There is a $3500 Budget, you all are driving in a v6 jeep wrangler. The
starting point is San Diego
  - we wanted to get the user to try and use the gas feature that we implemented, but we found out that it wasn't easy to get to the actual page. We also found that some users disliked the idea of putting their car make and model in. They suggested that we ask for the avg miles per gallon instead. I could see this being a better route because users are less likely to input their car's make, model, and year. Having an estimation based on the MPG(average miles per gallon) was going to be a better and easier way to implement this feature.


Task 3 
Imagine your buddy from Colorado is flying down to Los Angeles CA to visit
you. You guys want something fun to do for the day, but are not great
planners. Try and quickly find something fun to do for you and your friend.
Note: order of navigation/features used AND mistakes or backtracking
Within the $1000 budget:
  - This task was an intent to get the users to use the explore feature. What we realized from this task was that are button was not visible, rather than being on the homepage users had to find it in one of the menu tabs. This feature was well-liked by participants. Some of the users suggested we add filters to this, for certain budgets, trip lengths, and group types. 


## Findings

## Conclusions

## Caveats
Our main caveat is that we simply didn't get a wide enough breadth of users to test. All of the users were engineering college students who were taking a class about user experience. There was a complete and total lack of diversity.

Our secondary caveat is that due to the shortcomings of our prototype we relied heavily on the proctor to lead the user through what they might assume happens if buttons worked in a more obvious way.

Another caveat is that our user testing was done back to back with very short time constraints as users ran from test to test. Some tests were incomplete and thus there are some missing data points.

Finally, we have to caveat the fact that we are inexperienced in the art of proctoring these user tests and thus have likely missed many things said and done by the users that would've been of great value to our application, but due to time, stress, inexperience, and exhaustion we were unable to capture every detail to the level that we would've liked.
